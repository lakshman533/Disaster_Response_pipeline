{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download nltk libraries\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet', 'stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.metrics import classification_report,accuracy_score,f1_score,precision_score,recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterResponse1.db')\n",
    "df = pd.read_sql(\"SELECT * FROM Disaster\", engine)  \n",
    "X = df.message.values\n",
    "Y = df.drop(columns=['id', 'message', 'original', 'genre']).values\n",
    "category_names = np.array(df.drop(columns=['id', 'message', 'original', 'genre']).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "def replace_urls(text):\n",
    "    # get list of all urls using regex\n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    \n",
    "    # replace each url in text string with placeholder\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, 'urlplaceholder')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text=replace_urls(text)\n",
    "    text=re.sub(r'[^a-zA-Z0-9]', ' ', text).lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    words = [w for w in tokens if w not in stopwords.words(\"english\")]\n",
    "    lemmed = [WordNetLemmatizer().lemmatize(w, pos='v') for w in words]\n",
    "    stem_words = [PorterStemmer().stem(w) for w in lemmed]\n",
    "    return stem_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect',CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('clf',MultiOutputClassifier(estimator=RandomForestClassifier(n_jobs=-1)))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "\n",
    "# train classifier\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.45      0.52      1494\n",
      "          1       0.84      0.92      0.88      5015\n",
      "          2       0.62      0.18      0.28        45\n",
      "\n",
      "avg / total       0.79      0.81      0.79      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93      5453\n",
      "          1       0.78      0.42      0.55      1101\n",
      "\n",
      "avg / total       0.87      0.88      0.87      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6526\n",
      "          1       0.00      0.00      0.00        28\n",
      "\n",
      "avg / total       0.99      1.00      0.99      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.86      0.80      3824\n",
      "          1       0.75      0.59      0.66      2730\n",
      "\n",
      "avg / total       0.75      0.75      0.74      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.99      0.96      6010\n",
      "          1       0.58      0.08      0.14       544\n",
      "\n",
      "avg / total       0.89      0.92      0.89      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6207\n",
      "          1       0.81      0.07      0.14       347\n",
      "\n",
      "avg / total       0.94      0.95      0.93      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      6377\n",
      "          1       0.44      0.02      0.04       177\n",
      "\n",
      "avg / total       0.96      0.97      0.96      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6440\n",
      "          1       0.33      0.01      0.02       114\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6325\n",
      "          1       0.50      0.06      0.10       229\n",
      "\n",
      "avg / total       0.95      0.97      0.95      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6554\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6120\n",
      "          1       0.84      0.32      0.46       434\n",
      "\n",
      "avg / total       0.95      0.95      0.94      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.97      5858\n",
      "          1       0.80      0.57      0.67       696\n",
      "\n",
      "avg / total       0.93      0.94      0.93      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      6001\n",
      "          1       0.80      0.24      0.37       553\n",
      "\n",
      "avg / total       0.92      0.93      0.91      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6439\n",
      "          1       0.70      0.14      0.23       115\n",
      "\n",
      "avg / total       0.98      0.98      0.98      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6396\n",
      "          1       0.80      0.03      0.05       158\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6487\n",
      "          1       0.50      0.03      0.06        67\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      6323\n",
      "          1       0.60      0.13      0.21       231\n",
      "\n",
      "avg / total       0.96      0.97      0.96      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6260\n",
      "          1       0.83      0.15      0.25       294\n",
      "\n",
      "avg / total       0.96      0.96      0.95      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.99      0.93      5711\n",
      "          1       0.43      0.04      0.08       843\n",
      "\n",
      "avg / total       0.82      0.87      0.82      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97      6150\n",
      "          1       0.17      0.00      0.01       404\n",
      "\n",
      "avg / total       0.89      0.94      0.91      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6256\n",
      "          1       0.54      0.04      0.08       298\n",
      "\n",
      "avg / total       0.94      0.95      0.94      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98      6219\n",
      "          1       0.67      0.10      0.18       335\n",
      "\n",
      "avg / total       0.94      0.95      0.93      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6410\n",
      "          1       0.83      0.03      0.07       144\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6510\n",
      "          1       0.00      0.00      0.00        44\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6491\n",
      "          1       0.00      0.00      0.00        63\n",
      "\n",
      "avg / total       0.98      0.99      0.99      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6530\n",
      "          1       0.00      0.00      0.00        24\n",
      "\n",
      "avg / total       0.99      1.00      0.99      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      6484\n",
      "          1       0.00      0.00      0.00        70\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      6283\n",
      "          1       0.10      0.00      0.01       271\n",
      "\n",
      "avg / total       0.92      0.96      0.94      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.96      0.91      4716\n",
      "          1       0.85      0.61      0.71      1838\n",
      "\n",
      "avg / total       0.86      0.86      0.85      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6016\n",
      "          1       0.89      0.41      0.56       538\n",
      "\n",
      "avg / total       0.94      0.95      0.94      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.96      5927\n",
      "          1       0.79      0.37      0.50       627\n",
      "\n",
      "avg / total       0.92      0.93      0.92      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      6495\n",
      "          1       0.56      0.08      0.15        59\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      5930\n",
      "          1       0.90      0.73      0.80       624\n",
      "\n",
      "avg / total       0.96      0.97      0.96      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      6425\n",
      "          1       0.65      0.10      0.17       129\n",
      "\n",
      "avg / total       0.98      0.98      0.97      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6216\n",
      "          1       0.54      0.04      0.08       338\n",
      "\n",
      "avg / total       0.93      0.95      0.93      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.97      0.91      5310\n",
      "          1       0.74      0.33      0.45      1244\n",
      "\n",
      "avg / total       0.84      0.85      0.83      6554\n",
      "\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for ids in range(y_test.shape[-1]):\n",
    "    print(classification_report(y_test[:,ids], y_pred[:,ids]))\n",
    "    print(\"------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Returns the accuracy, precision and recall and f1 scores of the two same shape numpy arrays `y_true` and `y_pred`.\n",
    "\n",
    "    INPUTS:\n",
    "        y_true - Numpy array object - A (1 x n) vector of true values\n",
    "        y_pred - Numpy array object - A (1 x n) vector of predicted values\n",
    "        \n",
    "    OUPUT:\n",
    "        dict_scores - Python dict - A dictionary of accuracy, precision and recall and f1 scores of `y_true` and `y_pred`.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute the accuracy score of y_true and y_pred\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Compute the precision score of y_true and y_pred\n",
    "    precision =round( precision_score(y_true, y_pred, average='micro'))\n",
    "    \n",
    "    # Compute the recall score of y_true and y_pred\n",
    "    recall = recall_score(y_true, y_pred, average='micro')\n",
    "    \n",
    "    # Compute the recall score of y_true and y_pred\n",
    "    f_1 = f1_score(y_true, y_pred, average='micro')\n",
    "    \n",
    "    # A dictionary of accuracy, precision and recall and f1 scores of `y_true` and `y_pred`\n",
    "    dict_scores = {\n",
    "        'Accuracy': accuracy, \n",
    "        'Precision': precision, \n",
    "        'Recall': recall, \n",
    "        'F1 Score': f_1\n",
    "    }\n",
    "    \n",
    "    return dict_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.805920</td>\n",
       "      <td>0.805920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.805920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.882972</td>\n",
       "      <td>0.882972</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.882972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.995728</td>\n",
       "      <td>0.995728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.747788</td>\n",
       "      <td>0.747788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.747788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.918828</td>\n",
       "      <td>0.918828</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.918828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.950107</td>\n",
       "      <td>0.950107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.972841</td>\n",
       "      <td>0.972841</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.982453</td>\n",
       "      <td>0.982453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.965060</td>\n",
       "      <td>0.965060</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>child_alone</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.950870</td>\n",
       "      <td>0.950870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.939274</td>\n",
       "      <td>0.939274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.939274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.930729</td>\n",
       "      <td>0.930729</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.930729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.983827</td>\n",
       "      <td>0.983827</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.976350</td>\n",
       "      <td>0.976350</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.989777</td>\n",
       "      <td>0.989777</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.966280</td>\n",
       "      <td>0.966280</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.960482</td>\n",
       "      <td>0.960482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.869698</td>\n",
       "      <td>0.869698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.869698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.937138</td>\n",
       "      <td>0.937138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.937138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.954837</td>\n",
       "      <td>0.954837</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.951480</td>\n",
       "      <td>0.951480</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.978639</td>\n",
       "      <td>0.978639</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.993134</td>\n",
       "      <td>0.993134</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.990235</td>\n",
       "      <td>0.990235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.996338</td>\n",
       "      <td>0.996338</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.989319</td>\n",
       "      <td>0.989319</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.957431</td>\n",
       "      <td>0.957431</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.859017</td>\n",
       "      <td>0.859017</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.859017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>0.947055</td>\n",
       "      <td>0.947055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.930272</td>\n",
       "      <td>0.930272</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.930272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.991150</td>\n",
       "      <td>0.991150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.965975</td>\n",
       "      <td>0.965975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.965975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.981233</td>\n",
       "      <td>0.981233</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.948734</td>\n",
       "      <td>0.948734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.850320</td>\n",
       "      <td>0.850320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.850320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy  F1 Score  Precision    Recall\n",
       "related                 0.805920  0.805920        1.0  0.805920\n",
       "request                 0.882972  0.882972        1.0  0.882972\n",
       "offer                   0.995728  0.995728        1.0  0.995728\n",
       "aid_related             0.747788  0.747788        1.0  0.747788\n",
       "medical_help            0.918828  0.918828        1.0  0.918828\n",
       "medical_products        0.950107  0.950107        1.0  0.950107\n",
       "search_and_rescue       0.972841  0.972841        1.0  0.972841\n",
       "security                0.982453  0.982453        1.0  0.982453\n",
       "military                0.965060  0.965060        1.0  0.965060\n",
       "child_alone             1.000000  1.000000        1.0  1.000000\n",
       "water                   0.950870  0.950870        1.0  0.950870\n",
       "food                    0.939274  0.939274        1.0  0.939274\n",
       "shelter                 0.930729  0.930729        1.0  0.930729\n",
       "clothing                0.983827  0.983827        1.0  0.983827\n",
       "money                   0.976350  0.976350        1.0  0.976350\n",
       "missing_people          0.989777  0.989777        1.0  0.989777\n",
       "refugees                0.966280  0.966280        1.0  0.966280\n",
       "death                   0.960482  0.960482        1.0  0.960482\n",
       "other_aid               0.869698  0.869698        1.0  0.869698\n",
       "infrastructure_related  0.937138  0.937138        1.0  0.937138\n",
       "transport               0.954837  0.954837        1.0  0.954837\n",
       "buildings               0.951480  0.951480        1.0  0.951480\n",
       "electricity             0.978639  0.978639        1.0  0.978639\n",
       "tools                   0.993134  0.993134        1.0  0.993134\n",
       "hospitals               0.990235  0.990235        1.0  0.990235\n",
       "shops                   0.996338  0.996338        1.0  0.996338\n",
       "aid_centers             0.989319  0.989319        1.0  0.989319\n",
       "other_infrastructure    0.957431  0.957431        1.0  0.957431\n",
       "weather_related         0.859017  0.859017        1.0  0.859017\n",
       "floods                  0.947055  0.947055        1.0  0.947055\n",
       "storm                   0.930272  0.930272        1.0  0.930272\n",
       "fire                    0.991150  0.991150        1.0  0.991150\n",
       "earthquake              0.965975  0.965975        1.0  0.965975\n",
       "cold                    0.981233  0.981233        1.0  0.981233\n",
       "other_weather           0.948734  0.948734        1.0  0.948734\n",
       "direct_report           0.850320  0.850320        1.0  0.850320"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabulate_metric_scores = lambda y_test, y_pred : pd.DataFrame([get_scores(y_test[:, ids], y_pred[:, ids]) for ids in range(y_test.shape[-1])], index=category_names)\n",
    "\n",
    "tabulate_metric_scores(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "           strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "           tokenizer=<function tokenize at 0x7ffa4edab488>, vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       "  ('clf',\n",
       "   MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "               max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "               oob_score=False, random_state=None, verbose=0,\n",
       "               warm_start=False),\n",
       "              n_jobs=1))],\n",
       " 'vect': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=<function tokenize at 0x7ffa4edab488>, vocabulary=None),\n",
       " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
       " 'clf': MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       "            n_jobs=1),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'clf__estimator__bootstrap': True,\n",
       " 'clf__estimator__class_weight': None,\n",
       " 'clf__estimator__criterion': 'gini',\n",
       " 'clf__estimator__max_depth': None,\n",
       " 'clf__estimator__max_features': 'auto',\n",
       " 'clf__estimator__max_leaf_nodes': None,\n",
       " 'clf__estimator__min_impurity_decrease': 0.0,\n",
       " 'clf__estimator__min_impurity_split': None,\n",
       " 'clf__estimator__min_samples_leaf': 1,\n",
       " 'clf__estimator__min_samples_split': 2,\n",
       " 'clf__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__estimator__n_estimators': 10,\n",
       " 'clf__estimator__n_jobs': -1,\n",
       " 'clf__estimator__oob_score': False,\n",
       " 'clf__estimator__random_state': None,\n",
       " 'clf__estimator__verbose': 0,\n",
       " 'clf__estimator__warm_start': False,\n",
       " 'clf__estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False),\n",
       " 'clf__n_jobs': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'tfidf__norm': ['l1','l2'],\n",
    "              'clf__estimator__criterion': [\"gini\", \"entropy\"]\n",
    "    \n",
    "             }\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.807751</td>\n",
       "      <td>0.807751</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.807751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.881141</td>\n",
       "      <td>0.881141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.881141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.994812</td>\n",
       "      <td>0.994812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.747177</td>\n",
       "      <td>0.747177</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.747177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.924779</td>\n",
       "      <td>0.924779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.924779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.947513</td>\n",
       "      <td>0.947513</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.974214</td>\n",
       "      <td>0.974214</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.983827</td>\n",
       "      <td>0.983827</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.968874</td>\n",
       "      <td>0.968874</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>child_alone</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.953616</td>\n",
       "      <td>0.953616</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.953616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.934544</td>\n",
       "      <td>0.934544</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.934544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.931797</td>\n",
       "      <td>0.931797</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.985810</td>\n",
       "      <td>0.985810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.985810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.975282</td>\n",
       "      <td>0.975282</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.988557</td>\n",
       "      <td>0.988557</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.970095</td>\n",
       "      <td>0.970095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.962771</td>\n",
       "      <td>0.962771</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.874886</td>\n",
       "      <td>0.874886</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.874886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.935002</td>\n",
       "      <td>0.935002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.935002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.961092</td>\n",
       "      <td>0.961092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.953464</td>\n",
       "      <td>0.953464</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.953464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.979707</td>\n",
       "      <td>0.979707</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.993897</td>\n",
       "      <td>0.993897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.989319</td>\n",
       "      <td>0.989319</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.995880</td>\n",
       "      <td>0.995880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.988404</td>\n",
       "      <td>0.988404</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.954379</td>\n",
       "      <td>0.954379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.860391</td>\n",
       "      <td>0.860391</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.860391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>0.940494</td>\n",
       "      <td>0.940494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.931950</td>\n",
       "      <td>0.931950</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.990082</td>\n",
       "      <td>0.990082</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.966738</td>\n",
       "      <td>0.966738</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.978639</td>\n",
       "      <td>0.978639</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.949496</td>\n",
       "      <td>0.949496</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.949496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.848642</td>\n",
       "      <td>0.848642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.848642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy  F1 Score  Precision    Recall\n",
       "related                 0.807751  0.807751        1.0  0.807751\n",
       "request                 0.881141  0.881141        1.0  0.881141\n",
       "offer                   0.994812  0.994812        1.0  0.994812\n",
       "aid_related             0.747177  0.747177        1.0  0.747177\n",
       "medical_help            0.924779  0.924779        1.0  0.924779\n",
       "medical_products        0.947513  0.947513        1.0  0.947513\n",
       "search_and_rescue       0.974214  0.974214        1.0  0.974214\n",
       "security                0.983827  0.983827        1.0  0.983827\n",
       "military                0.968874  0.968874        1.0  0.968874\n",
       "child_alone             1.000000  1.000000        1.0  1.000000\n",
       "water                   0.953616  0.953616        1.0  0.953616\n",
       "food                    0.934544  0.934544        1.0  0.934544\n",
       "shelter                 0.931797  0.931797        1.0  0.931797\n",
       "clothing                0.985810  0.985810        1.0  0.985810\n",
       "money                   0.975282  0.975282        1.0  0.975282\n",
       "missing_people          0.988557  0.988557        1.0  0.988557\n",
       "refugees                0.970095  0.970095        1.0  0.970095\n",
       "death                   0.962771  0.962771        1.0  0.962771\n",
       "other_aid               0.874886  0.874886        1.0  0.874886\n",
       "infrastructure_related  0.935002  0.935002        1.0  0.935002\n",
       "transport               0.961092  0.961092        1.0  0.961092\n",
       "buildings               0.953464  0.953464        1.0  0.953464\n",
       "electricity             0.979707  0.979707        1.0  0.979707\n",
       "tools                   0.993897  0.993897        1.0  0.993897\n",
       "hospitals               0.989319  0.989319        1.0  0.989319\n",
       "shops                   0.995880  0.995880        1.0  0.995880\n",
       "aid_centers             0.988404  0.988404        1.0  0.988404\n",
       "other_infrastructure    0.954379  0.954379        1.0  0.954379\n",
       "weather_related         0.860391  0.860391        1.0  0.860391\n",
       "floods                  0.940494  0.940494        1.0  0.940494\n",
       "storm                   0.931950  0.931950        1.0  0.931950\n",
       "fire                    0.990082  0.990082        1.0  0.990082\n",
       "earthquake              0.966738  0.966738        1.0  0.966738\n",
       "cold                    0.978639  0.978639        1.0  0.978639\n",
       "other_weather           0.949496  0.949496        1.0  0.949496\n",
       "direct_report           0.848642  0.848642        1.0  0.848642"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabulate_metric_scores = lambda y_test, y_pred : pd.DataFrame([get_scores(y_test[:, ids], y_pred[:, ids]) for ids in range(y_test.shape[-1])], index=category_names)\n",
    "\n",
    "tabulate_metric_scores(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MLpipeline.pkl', 'wb') as file:\n",
    "    pickle.dump(cv, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
